# Файл docker-compose.yml — это YAML-файл, описывающий многоконтейнерное приложение.
# Он позволяет определить сервисы (контейнеры), сети, тома и другие настройки в одном месте.

# Основной ключ, под которым описываются все сервисы (контейнеры).
services:
  # Имя сервиса. Может быть любым, в данном случае — 'ollama'.
  ollama:
    # Указывает Docker-образ, из которого будет создан контейнер.
    # В данном случае используется образ 'ollama/ollama' с тегом '0.9.6'.
    image: ollama/ollama:0.9.6

    # Устанавливает имя контейнера. Если не указано, Docker генерирует имя автоматически.
    # В данном случае контейнер будет называться 'ollama'.
    container_name: "ollama"

    # Определяет политику перезапуска контейнера.
    # 'unless-stopped' означает, что контейнер будет перезапускаться при сбоях или перезапуске Docker,
    # если только он не был остановлен вручную.
    restart: unless-stopped

    # Указывает порты, которые будут доступны другим контейнерам в той же сети.
    # ВАЖНО: 'expose' НЕ делает порт доступным снаружи хоста (с твоего компьютера).
    # Он только объявляет, что контейнер использует порт 11434.
    # Если хочешь получить доступ извне, используй 'ports' вместо 'expose'.
    expose:
      - 11434

    # Определяет тома (bind mounts или named volumes), которые будут смонтированы в контейнер.
    # '.ollama_data:/root/.ollama' означает:
    # - '.ollama_data' — папка на хосте (в текущей директории).
    # - '/root/.ollama' — путь внутри контейнера, куда будет смонтирована папка.
    # Это позволяет сохранять данные (например, модели Ollama) между перезапусками контейнера.
    volumes:
      - ./.ollama_data:/root/.ollama

    # Подключает контейнер к одной или нескольким Docker-сетям.
    # В данном случае — к сети с именем 'devserver'.
    # Сети позволяют контейнерам обмениваться данными между собой.
    networks:
      - devserver

    # Это закомментированная секция.
    # Она показывает, как можно настроить использование GPU через Docker Compose.
    # Если раскомментировать и запустить на системе с NVIDIA GPU и драйверами,
    # Ollama сможет использовать GPU для ускорения работы моделей.
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #       - driver: nvidia
    #         count: all
    #         capabilities: [gpu]

# Здесь определяются все Docker-сети, используемые в этом compose-файле.
networks:
  # Имя сети — 'devserver'.
  devserver:
    # 'external: false' означает, что сеть будет создана автоматически Docker Compose.
    # Если бы было 'external: true', то сеть должна была бы существовать заранее.
    external: false